<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>deeplenstronomy.deeplenstronomy API documentation</title>
<meta name="description" content="The main module for dataset generation." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>deeplenstronomy.deeplenstronomy</code></h1>
</header>
<section id="section-intro">
<p>The main module for dataset generation.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;The main module for dataset generation.&#34;&#34;&#34;

import os
import random
import sys
import time

import h5py
import numpy as np
import pandas as pd

from deeplenstronomy.input_reader import Organizer, Parser
from deeplenstronomy.image_generator import ImageGenerator
from deeplenstronomy.utils import draw_from_user_dist, organize_image_backgrounds, read_images
from deeplenstronomy import surveys

class Dataset():
    def __init__(self, config=None, save=False, store=True):
        &#34;&#34;&#34;
        Create a dataset. If config file or config dict is supplied, generate it.

        Args:
            config (str or dict, optional, default=None): name of yaml configuration file
                specifying dataset characteristics or a pre-parsed yaml file as a dictionary 
            store (bool, optional, default=True): store the generated data as attributes of this object
            save (bool, optional, default=False): save the generated data to disk
        &#34;&#34;&#34;
        
        if config:
            make_dataset(config, dataset=self, save=save, store=store)
        return

    def update_param(self, new_param_dict, configuration):
        &#34;&#34;&#34;
        Update single parameters to new values.

        Args:
            new_param_dict (dict): {&#39;param_1_name&#39;: new_value_1, &#39;param_2_name&#39;: new_value_2, ...}
            configuration (str): like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc...     
        &#34;&#34;&#34;
        # Put in the updated values
        for new_param, new_value in new_param_dict.items():
            exec(&#34;self.config_dict&#34; + self._locate(new_param, configuration) + &#34; = new_value&#34;)
            
        return

    def update_param_dist(self, new_param_dist_dict, configuration):
        &#34;&#34;&#34;
        Update the distribution from which a parameter is drawn.

        Args:
            new_param_dist_dict (dict): 
              Should look like this
              
                  {&#39;param_1_name&#39;: {&#39;name&#39;: &#39;uniform&#39;,
                                  &#39;parameters&#39;: {&#39;minimum&#39;: new_value_1,
                                                 &#39;maximum&#39;: new_value_2}},
                  &#39;param_2_name&#39;: {&#39;name&#39;: &#39;uniform&#39;,
                                  &#39;parameters&#39;: {&#39;minimum&#39;: new_value_3,
                                                 &#39;maximum&#39;: new_value_4}}, ...}   
            
            configuration (str):  like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc...
        &#34;&#34;&#34;
        # Put in the updated distributions
        for new_param, new_dist_info in new_param_dist_dict.items():
            location = self._locate(new_param, configuration)
            exec(&#34;self.config_dict&#34; + location + &#34; = {&#39;DISTRIBUTION&#39;: {&#39;NAME&#39;: &#39;&#39;, &#39;PARAMETERS&#39;: {}}}&#34;)
            exec(&#34;self.config_dict&#34; + location + &#34;[&#39;DISTRIBUTION&#39;][&#39;NAME&#39;] = new_dist_info[&#39;name&#39;]&#34;)
            for new_dist_param, new_dist_param_value in new_dist_info[&#39;parameters&#39;].items():
                exec(&#34;self.config_dict&#34; + location + &#34;[&#39;DISTRIBUTION&#39;][&#39;PARAMETERS&#39;][new_dist_param] = new_dist_param_value&#34;)

        return

    
    def _locate(self, param, configuration):
        &#34;&#34;&#34;
        Find the path to the desired parameter in the main dictionary

        :param param: the name of the parameter you want to find the path for
        :param configuration: like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc... 
        :return: the path to the parameter
        &#34;&#34;&#34;
        if param[-1] in self.config_dict[&#39;SURVEY&#39;][&#39;PARAMETERS&#39;][&#39;BANDS&#39;].split(&#39;,&#39;):
            # Trim the band if the user left it in
            param = param[:-2]

        # DATASET- allowed params
        if param in [&#39;SIZE&#39;, &#39;OUTDIR&#39;]:
            return &#34;[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # COSMOLOGY
        elif param in [&#39;H0&#39;, &#39;Om0&#39;, &#39;Tcmb0&#39;, &#39;Neff&#39;, &#39;m_nu&#39;, &#39;Ob0&#39;]:
            return &#34;[&#39;COSMOLOGY&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # IMAGE
        elif param in [&#39;exposure_time&#39;, &#39;numPix&#39;, &#39;pixel_scale&#39;, &#39;psf_type&#39;, &#39;read_noise&#39;, &#39;ccd_gain&#39;]:
            return &#34;[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # SURVEY
        elif param in [&#39;BANDS&#39;, &#39;seeing&#39;, &#39;magnitude_zero_point&#39;, &#39;sky_brightness&#39;, &#39;num_exposures&#39;]:
            return &#34;[&#39;SURVEY&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # NOISE
        elif param[0:5] == &#39;NOISE&#39;:
            # type of noise
            if param[-4:] == &#39;NAME&#39;:
                return &#34;[&#39;GEOMETRY&#39;][&#39;{0}&#39;][&#39;{1}&#39;]&#34;.format(configuration, param.split(&#39;-&#39;)[0])
            # noise properties
            else:
                noise_name = self.config_dict[&#39;GEOMETRY&#39;][configuration][param.split(&#39;-&#39;)[0]]
                for k, v in self.config_dict[&#39;SPECIES&#39;].items():
                    for v_key in v.keys():
                        if v_key[0:5] == &#39;NOISE&#39;:
                            if v[&#39;NAME&#39;] == noise_name:
                                return &#34;[&#39;SPECIES&#39;][&#39;{0}&#39;][&#39;PARAMETERS&#39;][&#39;{1}&#39;]&#34;.format(k, param.split(&#39;-&#39;)[-1])
            
        # GEOMETRY and SPECIES
        elif param[0:5] == &#39;PLANE&#39;:
            # redshift
            if param[-8:] == &#39;REDSHIFT&#39;:
                return &#34;[&#39;GEOMETRY&#39;][&#39;{0}&#39;][&#39;{1}&#39;][&#39;PARAMETERS&#39;][&#39;REDSHIFT&#39;]&#34;.format(configuration, param.split(&#39;-&#39;)[0])
            # timeseries - not available yet
            
            # species
            else:
                obj_name = self.config_dict[&#39;GEOMETRY&#39;][configuration][param.split(&#39;-&#39;)[0]][param.split(&#39;-&#39;)[1]]
                for k, v in self.config_dict[&#39;SPECIES&#39;].items():
                    if &#39;NAME&#39; in v.keys():
                        if obj_name == self.config_dict[&#39;SPECIES&#39;][k][&#39;NAME&#39;]:
                            return &#34;[&#39;SPECIES&#39;][&#39;{0}&#39;][&#39;{1}&#39;][&#39;PARAMETERS&#39;][&#39;{2}&#39;]&#34;.format(k, param.split(&#39;-&#39;)[2], param.split(&#39;-&#39;)[-1])
                print(&#34;If you&#39;re seeing this message, you&#39;re trying to update something I wasn&#39;t prepared for.\nShoot me a message on Slack&#34;)
        else:
            print(&#34;If you&#39;re seeing this message, you&#39;re trying to update something I wasn&#39;t prepared for.\nShoot me a message on Slack&#34;)

        
    def regenerate(self, **make_dataset_args):
        &#34;&#34;&#34;
        Using the dictionary stored in self.config_dict, make a new dataset
        
        Args:
            make_dataset_args (dict): arguments supplied to make_dataset when original dataset was generated
        &#34;&#34;&#34;
        params = dict(**make_dataset_args)
        params[&#39;config&#39;] = self.config_dict
        params[&#39;dataset&#39;] = self
        make_dataset(**params)
        return


    def search(self, param_name):
        &#34;&#34;&#34;
        Find all USERDIST column headers for a parameter.
        
        Args:
            param_name (str): the parameter name to search for
            
        Returns:
            dict: keys contain object names, values contain a list of all possible USERDIST column headers
        &#34;&#34;&#34;
        obj_paths = [&#39;[&#34;&#39; + x[9:].replace(&#39;.&#39;, &#39;&#34;][&#34;&#39;) + &#39;&#34;]&#39; for x in self.config_dict.keypaths() if x.startswith(&#34;GEOMETRY&#34;) and x.find(&#34;OBJECT_&#34;) != -1]
        obj_names = []
        for x in obj_paths:
            obj_names.append(eval(&#39;self.config_dict[&#34;GEOMETRY&#34;]&#39; + x))
        species_paths = [&#39;[&#34;&#39; + x.replace(&#39;.&#39;, &#39;&#34;][&#34;&#39;) + &#39;&#34;]&#39; for x in self.config_dict.keypaths() if x.startswith(&#34;SPECIES&#34;) and x.endswith(&#34;NAME&#34;) and x.find(&#34;LIGHT_PROFILE_&#34;) == -1 and x.find(&#34;MASS_PROFILE_&#34;) == -1 and x.find(&#34;SHEAR_PROFILE_&#34;) == -1]
        species_names = []
        for x in species_paths:
            species_names.append(eval(&#39;self.config_dict&#39; + x))
    
        paths = []
        for obj_idx, obj_name in enumerate(obj_names):
            for species_idx, species_name in enumerate(species_names):
                if obj_name == species_name:
                    paths.append({&#39;name&#39;: obj_name,
                                  &#39;obj_path&#39;: obj_paths[obj_idx].replace(&#39;&#34;][&#34;&#39;, &#39;.&#39;)[2:-2],
                                  &#39;spe_path&#39;: species_paths[species_idx].replace(&#39;&#34;][&#34;&#39;, &#39;.&#39;)[2:-6]})
                    
        output_dict = {} 
        for p in paths:

            hr_paths = [p[&#39;obj_path&#39;] + &#39;.&#39; + x.replace(&#39;.PARAMETERS.&#39;, &#39;.&#39;)[len(p[&#39;spe_path&#39;]):] for x in self.config_dict.keypaths() if x.startswith(p[&#39;spe_path&#39;]) and x.find(param_name) != -1]
            output_paths = []
            for hr_path in hr_paths:
                if hr_path.find(&#39;DISTRIBUTION&#39;) != -1:
                    # not recommended to use this feature to update parameters in distributions
                    continue
                
                for band in self.bands:
                    output_paths.append(hr_path.replace(&#39;.&#39;, &#39;-&#39;) + &#39;-&#39; + band)
                    
            if len(output_paths) == 0:
                continue

            if p[&#39;name&#39;] in output_dict.keys():
                output_dict[p[&#39;name&#39;]] += output_paths
            else:
                output_dict[p[&#39;name&#39;]] = output_paths
            
        return output_dict


    
def _flatten_image_info(sim_dict):
    &#34;&#34;&#34;
    Sim dict will have structure 
        {&#39;g&#39;: {&#39;param1&#39;: value1}, &#39;r&#39;: {&#39;param1&#39;: value2} ...}
    This function will change the structure to
        {&#39;param1_g&#39;: value1, &#39;param1_r&#39;: value2, ...}

    :param sim_dict: input sim_dict for ImageGenerator class
    :returns out_dict: flattened sim_dict
    &#34;&#34;&#34;
    out_dict = {}
    for band, v in sim_dict.items():
        for sim_param, sim_value in v.items():
            out_dict[sim_param + &#39;-&#39; + band] = sim_value

    return out_dict
    
def _get_forced_sim_inputs(forced_inputs, configurations, bands):

    force_param_inputs = {}
    for force_params in forced_inputs.values():
        for name_idx, name in enumerate(force_params[&#39;names&#39;]):
            prefices, suffices = [], []
            # Configuration dependence  
            if name.startswith(&#34;CONFIGURATION&#34;):
                prefices = [name.split(&#39;-&#39;)[0]]
                param_name = &#39;-&#39;.join(name.split(&#39;-&#39;)[1:])
            else:
                prefices = configurations[:]
                param_name = name
            # Color dependence
            for b in bands:
                if name.endswith(&#39;-&#39; + b):
                    suffices = [b]
                    param_name = &#39;-&#39;.join(param_name.split(&#39;-&#39;)[:-1])
                    break
            if len(suffices) == 0:
                suffices = bands[:]
                param_name = param_name # this is not necessary at all, but makes me feel good inside seeing it match with the other blocks

            # Duplicate drawn values to necessary configurations / bands
            for prefix in prefices:
                for suffix in suffices:
                    if len(np.shape(force_params[&#39;values&#39;])) == 1:
                        force_param_inputs[(prefix, param_name, suffix)] = force_params[&#39;values&#39;]
                    else:
                        #numpy array for multiple dimensions
                        force_param_inputs[(prefix, param_name, suffix)] = force_params[&#39;values&#39;][:,name_idx]

    return force_param_inputs

def _check_survey(survey):
    if survey is None:
        return True
    else:
        return survey in dir(surveys)   

def _format_time(elapsed_time):
    &#34;&#34;&#34;
    Format a number of seconds as a HHMMSS string

    :param elapsed_time: float, an amount of time in seconds
    :return time_string: a formatted string of the elapsed time
    &#34;&#34;&#34;
    hours = elapsed_time // 3600
    minutes = (elapsed_time - hours * 3600) // 60
    seconds = elapsed_time - (hours * 3600) - (minutes * 60)
    return &#34;%i H %i M %i S&#34; %(hours, minutes, seconds)

def make_dataset(config, dataset=None, save_to_disk=False, store_in_memory=True,
                 verbose=False, store_sample=False, image_file_format=&#39;npy&#39;,
                 survey=None, return_planes=False, skip_image_generation=False,
                 solve_lens_equation=False):
    &#34;&#34;&#34;
    Generate a dataset from a config file.

    Args:
        config (str or dict): name of yaml file specifying dataset characteristics or pre-parsed yaml file as dictionary
        verbose (bool, optional, default=False): print progress and status  updates at runtime
        store_in_memory (bool, optional, default=True): save images and metadata as attributes 
        save_to_disk (bool, optional, default=False): save images and metadata to disk   
        store_sample (bool, optional, default=False): save five images and metadata as attribute 
        image_file_format (str, optional, default=&#39;npy&#39;): outfile format type, options include (&#39;npy&#39;, &#39;h5&#39;)
        survey (str or None, optional, default=None): a default astronomical survey to use 
        return_planes (bool, optional, default=False): return the lens, source, noise, and point source planes of the simulated images
        skip_image_generation (bool, optional, default=False): skip image generation
        solve_lens_equation (bool, optional, default=False): calculate the source positions
        
    Returns:
        dataset (Dataset): and instance of the Dataset class

    Raises:
        RuntimeError: If `skip_image_generation == True` and `solve_lens_equation == True`
        RuntimeError: If `survey` is not a valid survey name
        
    &#34;&#34;&#34;

    if solve_lens_equation and skip_image_generation:
        raise RuntimeError(&#34;You cannot skip image generation and solve the lens equation&#34;)
    
    if dataset is None:
        dataset = Dataset()
    else:
        parser = dataset.parser

    # set arguments of dataset generation
    dataset.arguments = dict(**locals())

    if isinstance(config, dict):
        dataset.config_dict = config
    else:    
        # Store config file
        dataset.config_file = config
        
        # Parse the config file and store config dict
        if not _check_survey(survey):
            raise RuntimeError(&#34;survey={0} is not a valid survey.&#34;.format(survey))
        parser = Parser(config, survey=survey)
        dataset.config_dict = parser.config_dict

    # store parser
    dataset.parser = parser

    # Store top-level dataset info
    dataset.name = dataset.config_dict[&#39;DATASET&#39;][&#39;NAME&#39;]
    dataset.size = dataset.config_dict[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#39;SIZE&#39;]
    dataset.outdir = dataset.config_dict[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#39;OUTDIR&#39;]
    dataset.bands = dataset.config_dict[&#39;SURVEY&#39;][&#39;PARAMETERS&#39;][&#39;BANDS&#39;].split(&#39;,&#39;)
    try:
        dataset.seed = int(dataset.config_dict[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#34;SEED&#34;])
    except KeyError:
        dataset.seed = random.randint(0, 100)
    np.random.seed(dataset.seed)
    random.seed(dataset.seed)

    # Make the output directory if it doesn&#39;t exist already
    if save_to_disk:
        if not os.path.exists(dataset.outdir):
            os.mkdir(dataset.outdir)
    
    # Organize the configuration dict
    organizer = Organizer(dataset.config_dict, verbose=verbose)

    # Store configurations
    dataset.configurations = list(organizer.configuration_sim_dicts.keys())

    # Store species map
    dataset.species_map = organizer._species_map

    # If user-specified distributions exist, draw from them
    forced_inputs = {}
    for fp in parser.file_paths:
        filename = eval(&#34;parser.config_dict[&#39;&#34; + fp.replace(&#39;.&#39;, &#34;&#39;][&#39;&#34;) + &#34;&#39;]&#34; + &#34;[&#39;FILENAME&#39;]&#34;)
        mode = eval(&#34;parser.config_dict[&#39;&#34; + fp.replace(&#39;.&#39;, &#34;&#39;][&#39;&#34;) + &#34;&#39;]&#34; + &#34;[&#39;MODE&#39;]&#34;)
        try:
            step = eval(&#34;parser.config_dict[&#39;&#34; + fp.replace(&#39;.&#39;, &#34;&#39;][&#39;&#34;) + &#34;&#39;]&#34; + &#34;[&#39;STEP&#39;]&#34;)
        except KeyError:
            step = 10
        draw_param_names, draw_param_values = draw_from_user_dist(filename, dataset.size, mode, step)
        forced_inputs[filename] = {&#39;names&#39;: draw_param_names, &#39;values&#39;: draw_param_values}
    
    # Overwrite the configuration dict with any forced values from user distribtuions
    force_param_inputs = _get_forced_sim_inputs(forced_inputs, dataset.configurations, dataset.bands)

    for force_param, values in force_param_inputs.items():
        configuration, param_name, band = force_param
        warned = False

        sim_inputs = organizer.configuration_sim_dicts[configuration]
        for sim_input, val in zip(sim_inputs, values):
            if param_name in sim_input[band].keys():
                sim_input[band][param_name] = val
            else:
                if not warned:
                    print(&#34;WARNING: &#34; + param_name + &#34; is not present in the simulated dataset and may produce unexpected behavior. Use dataset.search(&lt;param name&gt;) to find all expected names&#34;)
                    warned = True
                    
    # Skip image generation if desired
    if skip_image_generation:
        # Handle metadata and return dataset object
        for configuration, sim_inputs in organizer.configuration_sim_dicts.items():
            metadata = [_flatten_image_info(image_info) for image_info in sim_inputs]
            metadata_df = pd.DataFrame(metadata)
            del metadata
            if save_to_disk:
                metadata_df.to_csv(&#39;{0}/{1}_metadata.csv&#39;.format(dataset.outdir, configuration), index=False)
            if store_in_memory:
                setattr(dataset, &#39;{0}_metadata&#39;.format(configuration), metadata_df)
        return dataset
                
    # Initialize the ImageGenerator
    ImGen = ImageGenerator(return_planes, solve_lens_equation)

    # Handle image backgrounds if they exist
    if len(parser.image_paths) &gt; 0:
        im_dir = parser.config_dict[&#39;BACKGROUNDS&#39;][&#34;PATH&#34;]
        image_backgrounds = read_images(im_dir, parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;], dataset.bands)
    else:
        image_backgrounds = np.zeros((len(dataset.bands), parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;], parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;]))[np.newaxis,:]
    
    # Simulate images
    for configuration, sim_inputs in organizer.configuration_sim_dicts.items():

        if verbose:
            print(&#34;Generating images for {0}&#34;.format(configuration))
            start_time = time.time()
            counter = 0
            total = len(sim_inputs)

        # Handle image backgrounds if they exist
        if len(parser.image_paths) &gt; 0 and configuration in parser.image_configurations:
            image_indices = organize_image_backgrounds(im_dir, len(image_backgrounds), [_flatten_image_info(sim_input) for sim_input in sim_inputs], configuration)
            additive_image_backgrounds = image_backgrounds[image_indices]
        else:
            image_indices = np.zeros(len(sim_inputs), dtype=int)
            temp_array = np.zeros((len(dataset.bands), parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;], parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;]))[np.newaxis,:]
            additive_image_backgrounds = temp_array[image_indices]
            
        metadata, images = [], []
        if return_planes:
            planes = []

        for image_info, image_idx in zip(sim_inputs, image_indices):
            # track progress if verbose
            if verbose:
                counter += 1
                if counter % 50 == 0:
                    progress = counter / total * 100
                    elapsed_time = time.time() - start_time
                    sys.stdout.write(&#39;\r\tProgress: %.1f %%  ---  Elapsed Time: %s&#39; %(progress, _format_time(elapsed_time)))
                    sys.stdout.flush()
            
            # Add background image index to image_info
            for band in dataset.bands:
                image_info[band][&#39;BACKGROUND_IDX&#39;] = image_idx
                
            # make the image
            simulated_image_data = ImGen.sim_image(image_info)
            if not return_planes:
                images.append(simulated_image_data[&#39;output_image&#39;])
            else:
                images.append(simulated_image_data[&#39;output_image&#39;])
                planes.append(np.array([simulated_image_data[&#39;output_lens_plane&#39;],
                                        simulated_image_data[&#39;output_source_plane&#39;],
                                        simulated_image_data[&#39;output_point_source_plane&#39;],
                                        simulated_image_data[&#39;output_noise_plane&#39;]]))

            # Add any additional metadata to the image info
            if len(simulated_image_data[&#39;additional_metadata&#39;]) != 0:
                for info in simulated_image_data[&#39;additional_metadata&#39;]:
                    band = info[&#39;PARAM_NAME&#39;].split(&#39;-&#39;)[-1]
                    param = &#39;-&#39;.join(info[&#39;PARAM_NAME&#39;].split(&#39;-&#39;)[0:-1])
                    image_info[band][param] = info[&#39;PARAM_VALUE&#39;]

            if solve_lens_equation:
                for band in dataset.bands:
                    image_info[band][&#39;x_mins&#39;] = &#39;;&#39;.join([str(x) for x in simulated_image_data[&#39;x_mins&#39;]])
                    image_info[band][&#39;y_mins&#39;] = &#39;;&#39;.join([str(x) for x in simulated_image_data[&#39;y_mins&#39;]])
                    image_info[band][&#39;num_source_images&#39;] = simulated_image_data[&#39;num_source_images&#39;]
                              
            # Save metadata for each simulated image 
            metadata.append(_flatten_image_info(image_info))

            # update the progress if in verbose mode
            if verbose:
                elapsed_time = time.time() - start_time
                if counter == len(sim_inputs):
                    sys.stdout.write(&#39;\r\tProgress: 100.0 %%  ---  Elapsed Time: %s\n&#39; %(_format_time(elapsed_time)))
                    sys.stdout.flush()

                              
        # Group images -- the array index will correspond to the id_num of the metadata
        configuration_images = np.array(images)

        # Group planes if requested
        if return_planes:
            configuration_planes = np.array(planes)

        # Add image backgrounds -- will just add zeros if no backgrounds have been specified
        configuration_images += additive_image_backgrounds
        
        # Convert the metadata to a dataframe
        metadata_df = pd.DataFrame(metadata)
        del metadata

        # Save the images and metadata to the outdir if desired (ideal for large simulation production)
        if save_to_disk:
            #Images
            if image_file_format == &#39;npy&#39;:
                np.save(&#39;{0}/{1}_images.npy&#39;.format(dataset.outdir, configuration), configuration_images)
                if return_planes:
                    np.save(&#39;{0}/{1}_planes.npy&#39;.format(dataset.outdir, configuration), configuration_planes)
            elif image_file_format == &#39;h5&#39;:
                hf = h5py.File(&#39;{0}/{1}_images.h5&#39;.format(dataset.outdir, configuration), &#39;w&#39;)
                hf.create_dataset(dataset.name, data=configuration_images)
                hf.close()
                if return_planes:
                    hf = h5py.File(&#39;{0}/{1}_planes.h5&#39;.format(dataset.outdir, configuration), &#39;w&#39;)
                    hf.create_dataset(dataset.name, data=configuration_planes)
                    hf.close()
            else:
                print(&#34;ERROR: {0} is not a supported argument for image_file_format&#34;.format(image_file_format))
            #Metadata
            metadata_df.to_csv(&#39;{0}/{1}_metadata.csv&#39;.format(dataset.outdir, configuration), index=False)

        # Store the images and metadata to the Dataset object (ideal for small scale testing)
        if store_in_memory:
            setattr(dataset, &#39;{0}_images&#39;.format(configuration), configuration_images)
            setattr(dataset, &#39;{0}_metadata&#39;.format(configuration), metadata_df)
            if return_planes:
                setattr(dataset, &#39;{0}_planes&#39;.format(configuration), configuration_planes)
        elif store_sample:
            setattr(dataset, &#39;{0}_images&#39;.format(configuration), configuration_images[0:5].copy())
            setattr(dataset, &#39;{0}_metadata&#39;.format(configuration), metadata_df.iloc[0:5].copy())
            del configuration_images
            del metadata_df                
            if return_planes:
                setattr(dataset, &#39;{0}_planes&#39;.format(configuration), configuration_planes[0:5].copy())
                del configuration_planes
        else:
            # Clean up things that are done to save space
            del configuration_images
            del metadata_df
            if return_planes:
                del configuration_planes

                
    return dataset

    
if __name__ == &#34;__main__&#34;:
    pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="deeplenstronomy.deeplenstronomy.make_dataset"><code class="name flex">
<span>def <span class="ident">make_dataset</span></span>(<span>config, dataset=None, save_to_disk=False, store_in_memory=True, verbose=False, store_sample=False, image_file_format='npy', survey=None, return_planes=False, skip_image_generation=False, solve_lens_equation=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a dataset from a config file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>str</code> or <code>dict</code></dt>
<dd>name of yaml file specifying dataset characteristics or pre-parsed yaml file as dictionary</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>print progress and status
updates at runtime</dd>
<dt><strong><code>store_in_memory</code></strong> :&ensp;<code>bool</code>, optional, default=<code>True</code></dt>
<dd>save images and metadata as attributes </dd>
<dt><strong><code>save_to_disk</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>save images and metadata to disk
</dd>
<dt><strong><code>store_sample</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>save five images and metadata as attribute </dd>
<dt>image_file_format (str, optional, default='npy'): outfile format type, options include ('npy', 'h5')</dt>
<dt><strong><code>survey</code></strong> :&ensp;<code>str</code> or <code>None</code>, optional, default=<code>None</code></dt>
<dd>a default astronomical survey to use </dd>
<dt><strong><code>return_planes</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>return the lens, source, noise, and point source planes of the simulated images</dd>
<dt><strong><code>skip_image_generation</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>skip image generation</dd>
<dt><strong><code>solve_lens_equation</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>calculate the source positions</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dataset (Dataset): and instance of the Dataset class</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If <code>skip_image_generation == True</code> and <code>solve_lens_equation == True</code></dd>
<dt><code>RuntimeError</code></dt>
<dd>If <code>survey</code> is not a valid survey name</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_dataset(config, dataset=None, save_to_disk=False, store_in_memory=True,
                 verbose=False, store_sample=False, image_file_format=&#39;npy&#39;,
                 survey=None, return_planes=False, skip_image_generation=False,
                 solve_lens_equation=False):
    &#34;&#34;&#34;
    Generate a dataset from a config file.

    Args:
        config (str or dict): name of yaml file specifying dataset characteristics or pre-parsed yaml file as dictionary
        verbose (bool, optional, default=False): print progress and status  updates at runtime
        store_in_memory (bool, optional, default=True): save images and metadata as attributes 
        save_to_disk (bool, optional, default=False): save images and metadata to disk   
        store_sample (bool, optional, default=False): save five images and metadata as attribute 
        image_file_format (str, optional, default=&#39;npy&#39;): outfile format type, options include (&#39;npy&#39;, &#39;h5&#39;)
        survey (str or None, optional, default=None): a default astronomical survey to use 
        return_planes (bool, optional, default=False): return the lens, source, noise, and point source planes of the simulated images
        skip_image_generation (bool, optional, default=False): skip image generation
        solve_lens_equation (bool, optional, default=False): calculate the source positions
        
    Returns:
        dataset (Dataset): and instance of the Dataset class

    Raises:
        RuntimeError: If `skip_image_generation == True` and `solve_lens_equation == True`
        RuntimeError: If `survey` is not a valid survey name
        
    &#34;&#34;&#34;

    if solve_lens_equation and skip_image_generation:
        raise RuntimeError(&#34;You cannot skip image generation and solve the lens equation&#34;)
    
    if dataset is None:
        dataset = Dataset()
    else:
        parser = dataset.parser

    # set arguments of dataset generation
    dataset.arguments = dict(**locals())

    if isinstance(config, dict):
        dataset.config_dict = config
    else:    
        # Store config file
        dataset.config_file = config
        
        # Parse the config file and store config dict
        if not _check_survey(survey):
            raise RuntimeError(&#34;survey={0} is not a valid survey.&#34;.format(survey))
        parser = Parser(config, survey=survey)
        dataset.config_dict = parser.config_dict

    # store parser
    dataset.parser = parser

    # Store top-level dataset info
    dataset.name = dataset.config_dict[&#39;DATASET&#39;][&#39;NAME&#39;]
    dataset.size = dataset.config_dict[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#39;SIZE&#39;]
    dataset.outdir = dataset.config_dict[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#39;OUTDIR&#39;]
    dataset.bands = dataset.config_dict[&#39;SURVEY&#39;][&#39;PARAMETERS&#39;][&#39;BANDS&#39;].split(&#39;,&#39;)
    try:
        dataset.seed = int(dataset.config_dict[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#34;SEED&#34;])
    except KeyError:
        dataset.seed = random.randint(0, 100)
    np.random.seed(dataset.seed)
    random.seed(dataset.seed)

    # Make the output directory if it doesn&#39;t exist already
    if save_to_disk:
        if not os.path.exists(dataset.outdir):
            os.mkdir(dataset.outdir)
    
    # Organize the configuration dict
    organizer = Organizer(dataset.config_dict, verbose=verbose)

    # Store configurations
    dataset.configurations = list(organizer.configuration_sim_dicts.keys())

    # Store species map
    dataset.species_map = organizer._species_map

    # If user-specified distributions exist, draw from them
    forced_inputs = {}
    for fp in parser.file_paths:
        filename = eval(&#34;parser.config_dict[&#39;&#34; + fp.replace(&#39;.&#39;, &#34;&#39;][&#39;&#34;) + &#34;&#39;]&#34; + &#34;[&#39;FILENAME&#39;]&#34;)
        mode = eval(&#34;parser.config_dict[&#39;&#34; + fp.replace(&#39;.&#39;, &#34;&#39;][&#39;&#34;) + &#34;&#39;]&#34; + &#34;[&#39;MODE&#39;]&#34;)
        try:
            step = eval(&#34;parser.config_dict[&#39;&#34; + fp.replace(&#39;.&#39;, &#34;&#39;][&#39;&#34;) + &#34;&#39;]&#34; + &#34;[&#39;STEP&#39;]&#34;)
        except KeyError:
            step = 10
        draw_param_names, draw_param_values = draw_from_user_dist(filename, dataset.size, mode, step)
        forced_inputs[filename] = {&#39;names&#39;: draw_param_names, &#39;values&#39;: draw_param_values}
    
    # Overwrite the configuration dict with any forced values from user distribtuions
    force_param_inputs = _get_forced_sim_inputs(forced_inputs, dataset.configurations, dataset.bands)

    for force_param, values in force_param_inputs.items():
        configuration, param_name, band = force_param
        warned = False

        sim_inputs = organizer.configuration_sim_dicts[configuration]
        for sim_input, val in zip(sim_inputs, values):
            if param_name in sim_input[band].keys():
                sim_input[band][param_name] = val
            else:
                if not warned:
                    print(&#34;WARNING: &#34; + param_name + &#34; is not present in the simulated dataset and may produce unexpected behavior. Use dataset.search(&lt;param name&gt;) to find all expected names&#34;)
                    warned = True
                    
    # Skip image generation if desired
    if skip_image_generation:
        # Handle metadata and return dataset object
        for configuration, sim_inputs in organizer.configuration_sim_dicts.items():
            metadata = [_flatten_image_info(image_info) for image_info in sim_inputs]
            metadata_df = pd.DataFrame(metadata)
            del metadata
            if save_to_disk:
                metadata_df.to_csv(&#39;{0}/{1}_metadata.csv&#39;.format(dataset.outdir, configuration), index=False)
            if store_in_memory:
                setattr(dataset, &#39;{0}_metadata&#39;.format(configuration), metadata_df)
        return dataset
                
    # Initialize the ImageGenerator
    ImGen = ImageGenerator(return_planes, solve_lens_equation)

    # Handle image backgrounds if they exist
    if len(parser.image_paths) &gt; 0:
        im_dir = parser.config_dict[&#39;BACKGROUNDS&#39;][&#34;PATH&#34;]
        image_backgrounds = read_images(im_dir, parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;], dataset.bands)
    else:
        image_backgrounds = np.zeros((len(dataset.bands), parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;], parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;]))[np.newaxis,:]
    
    # Simulate images
    for configuration, sim_inputs in organizer.configuration_sim_dicts.items():

        if verbose:
            print(&#34;Generating images for {0}&#34;.format(configuration))
            start_time = time.time()
            counter = 0
            total = len(sim_inputs)

        # Handle image backgrounds if they exist
        if len(parser.image_paths) &gt; 0 and configuration in parser.image_configurations:
            image_indices = organize_image_backgrounds(im_dir, len(image_backgrounds), [_flatten_image_info(sim_input) for sim_input in sim_inputs], configuration)
            additive_image_backgrounds = image_backgrounds[image_indices]
        else:
            image_indices = np.zeros(len(sim_inputs), dtype=int)
            temp_array = np.zeros((len(dataset.bands), parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;], parser.config_dict[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;numPix&#39;]))[np.newaxis,:]
            additive_image_backgrounds = temp_array[image_indices]
            
        metadata, images = [], []
        if return_planes:
            planes = []

        for image_info, image_idx in zip(sim_inputs, image_indices):
            # track progress if verbose
            if verbose:
                counter += 1
                if counter % 50 == 0:
                    progress = counter / total * 100
                    elapsed_time = time.time() - start_time
                    sys.stdout.write(&#39;\r\tProgress: %.1f %%  ---  Elapsed Time: %s&#39; %(progress, _format_time(elapsed_time)))
                    sys.stdout.flush()
            
            # Add background image index to image_info
            for band in dataset.bands:
                image_info[band][&#39;BACKGROUND_IDX&#39;] = image_idx
                
            # make the image
            simulated_image_data = ImGen.sim_image(image_info)
            if not return_planes:
                images.append(simulated_image_data[&#39;output_image&#39;])
            else:
                images.append(simulated_image_data[&#39;output_image&#39;])
                planes.append(np.array([simulated_image_data[&#39;output_lens_plane&#39;],
                                        simulated_image_data[&#39;output_source_plane&#39;],
                                        simulated_image_data[&#39;output_point_source_plane&#39;],
                                        simulated_image_data[&#39;output_noise_plane&#39;]]))

            # Add any additional metadata to the image info
            if len(simulated_image_data[&#39;additional_metadata&#39;]) != 0:
                for info in simulated_image_data[&#39;additional_metadata&#39;]:
                    band = info[&#39;PARAM_NAME&#39;].split(&#39;-&#39;)[-1]
                    param = &#39;-&#39;.join(info[&#39;PARAM_NAME&#39;].split(&#39;-&#39;)[0:-1])
                    image_info[band][param] = info[&#39;PARAM_VALUE&#39;]

            if solve_lens_equation:
                for band in dataset.bands:
                    image_info[band][&#39;x_mins&#39;] = &#39;;&#39;.join([str(x) for x in simulated_image_data[&#39;x_mins&#39;]])
                    image_info[band][&#39;y_mins&#39;] = &#39;;&#39;.join([str(x) for x in simulated_image_data[&#39;y_mins&#39;]])
                    image_info[band][&#39;num_source_images&#39;] = simulated_image_data[&#39;num_source_images&#39;]
                              
            # Save metadata for each simulated image 
            metadata.append(_flatten_image_info(image_info))

            # update the progress if in verbose mode
            if verbose:
                elapsed_time = time.time() - start_time
                if counter == len(sim_inputs):
                    sys.stdout.write(&#39;\r\tProgress: 100.0 %%  ---  Elapsed Time: %s\n&#39; %(_format_time(elapsed_time)))
                    sys.stdout.flush()

                              
        # Group images -- the array index will correspond to the id_num of the metadata
        configuration_images = np.array(images)

        # Group planes if requested
        if return_planes:
            configuration_planes = np.array(planes)

        # Add image backgrounds -- will just add zeros if no backgrounds have been specified
        configuration_images += additive_image_backgrounds
        
        # Convert the metadata to a dataframe
        metadata_df = pd.DataFrame(metadata)
        del metadata

        # Save the images and metadata to the outdir if desired (ideal for large simulation production)
        if save_to_disk:
            #Images
            if image_file_format == &#39;npy&#39;:
                np.save(&#39;{0}/{1}_images.npy&#39;.format(dataset.outdir, configuration), configuration_images)
                if return_planes:
                    np.save(&#39;{0}/{1}_planes.npy&#39;.format(dataset.outdir, configuration), configuration_planes)
            elif image_file_format == &#39;h5&#39;:
                hf = h5py.File(&#39;{0}/{1}_images.h5&#39;.format(dataset.outdir, configuration), &#39;w&#39;)
                hf.create_dataset(dataset.name, data=configuration_images)
                hf.close()
                if return_planes:
                    hf = h5py.File(&#39;{0}/{1}_planes.h5&#39;.format(dataset.outdir, configuration), &#39;w&#39;)
                    hf.create_dataset(dataset.name, data=configuration_planes)
                    hf.close()
            else:
                print(&#34;ERROR: {0} is not a supported argument for image_file_format&#34;.format(image_file_format))
            #Metadata
            metadata_df.to_csv(&#39;{0}/{1}_metadata.csv&#39;.format(dataset.outdir, configuration), index=False)

        # Store the images and metadata to the Dataset object (ideal for small scale testing)
        if store_in_memory:
            setattr(dataset, &#39;{0}_images&#39;.format(configuration), configuration_images)
            setattr(dataset, &#39;{0}_metadata&#39;.format(configuration), metadata_df)
            if return_planes:
                setattr(dataset, &#39;{0}_planes&#39;.format(configuration), configuration_planes)
        elif store_sample:
            setattr(dataset, &#39;{0}_images&#39;.format(configuration), configuration_images[0:5].copy())
            setattr(dataset, &#39;{0}_metadata&#39;.format(configuration), metadata_df.iloc[0:5].copy())
            del configuration_images
            del metadata_df                
            if return_planes:
                setattr(dataset, &#39;{0}_planes&#39;.format(configuration), configuration_planes[0:5].copy())
                del configuration_planes
        else:
            # Clean up things that are done to save space
            del configuration_images
            del metadata_df
            if return_planes:
                del configuration_planes

                
    return dataset</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="deeplenstronomy.deeplenstronomy.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>config=None, save=False, store=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a dataset. If config file or config dict is supplied, generate it.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>str</code> or <code>dict</code>, optional, default=<code>None</code></dt>
<dd>name of yaml configuration file
specifying dataset characteristics or a pre-parsed yaml file as a dictionary </dd>
<dt><strong><code>store</code></strong> :&ensp;<code>bool</code>, optional, default=<code>True</code></dt>
<dd>store the generated data as attributes of this object</dd>
<dt><strong><code>save</code></strong> :&ensp;<code>bool</code>, optional, default=<code>False</code></dt>
<dd>save the generated data to disk</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataset():
    def __init__(self, config=None, save=False, store=True):
        &#34;&#34;&#34;
        Create a dataset. If config file or config dict is supplied, generate it.

        Args:
            config (str or dict, optional, default=None): name of yaml configuration file
                specifying dataset characteristics or a pre-parsed yaml file as a dictionary 
            store (bool, optional, default=True): store the generated data as attributes of this object
            save (bool, optional, default=False): save the generated data to disk
        &#34;&#34;&#34;
        
        if config:
            make_dataset(config, dataset=self, save=save, store=store)
        return

    def update_param(self, new_param_dict, configuration):
        &#34;&#34;&#34;
        Update single parameters to new values.

        Args:
            new_param_dict (dict): {&#39;param_1_name&#39;: new_value_1, &#39;param_2_name&#39;: new_value_2, ...}
            configuration (str): like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc...     
        &#34;&#34;&#34;
        # Put in the updated values
        for new_param, new_value in new_param_dict.items():
            exec(&#34;self.config_dict&#34; + self._locate(new_param, configuration) + &#34; = new_value&#34;)
            
        return

    def update_param_dist(self, new_param_dist_dict, configuration):
        &#34;&#34;&#34;
        Update the distribution from which a parameter is drawn.

        Args:
            new_param_dist_dict (dict): 
              Should look like this
              
                  {&#39;param_1_name&#39;: {&#39;name&#39;: &#39;uniform&#39;,
                                  &#39;parameters&#39;: {&#39;minimum&#39;: new_value_1,
                                                 &#39;maximum&#39;: new_value_2}},
                  &#39;param_2_name&#39;: {&#39;name&#39;: &#39;uniform&#39;,
                                  &#39;parameters&#39;: {&#39;minimum&#39;: new_value_3,
                                                 &#39;maximum&#39;: new_value_4}}, ...}   
            
            configuration (str):  like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc...
        &#34;&#34;&#34;
        # Put in the updated distributions
        for new_param, new_dist_info in new_param_dist_dict.items():
            location = self._locate(new_param, configuration)
            exec(&#34;self.config_dict&#34; + location + &#34; = {&#39;DISTRIBUTION&#39;: {&#39;NAME&#39;: &#39;&#39;, &#39;PARAMETERS&#39;: {}}}&#34;)
            exec(&#34;self.config_dict&#34; + location + &#34;[&#39;DISTRIBUTION&#39;][&#39;NAME&#39;] = new_dist_info[&#39;name&#39;]&#34;)
            for new_dist_param, new_dist_param_value in new_dist_info[&#39;parameters&#39;].items():
                exec(&#34;self.config_dict&#34; + location + &#34;[&#39;DISTRIBUTION&#39;][&#39;PARAMETERS&#39;][new_dist_param] = new_dist_param_value&#34;)

        return

    
    def _locate(self, param, configuration):
        &#34;&#34;&#34;
        Find the path to the desired parameter in the main dictionary

        :param param: the name of the parameter you want to find the path for
        :param configuration: like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc... 
        :return: the path to the parameter
        &#34;&#34;&#34;
        if param[-1] in self.config_dict[&#39;SURVEY&#39;][&#39;PARAMETERS&#39;][&#39;BANDS&#39;].split(&#39;,&#39;):
            # Trim the band if the user left it in
            param = param[:-2]

        # DATASET- allowed params
        if param in [&#39;SIZE&#39;, &#39;OUTDIR&#39;]:
            return &#34;[&#39;DATASET&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # COSMOLOGY
        elif param in [&#39;H0&#39;, &#39;Om0&#39;, &#39;Tcmb0&#39;, &#39;Neff&#39;, &#39;m_nu&#39;, &#39;Ob0&#39;]:
            return &#34;[&#39;COSMOLOGY&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # IMAGE
        elif param in [&#39;exposure_time&#39;, &#39;numPix&#39;, &#39;pixel_scale&#39;, &#39;psf_type&#39;, &#39;read_noise&#39;, &#39;ccd_gain&#39;]:
            return &#34;[&#39;IMAGE&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # SURVEY
        elif param in [&#39;BANDS&#39;, &#39;seeing&#39;, &#39;magnitude_zero_point&#39;, &#39;sky_brightness&#39;, &#39;num_exposures&#39;]:
            return &#34;[&#39;SURVEY&#39;][&#39;PARAMETERS&#39;][&#39;{0}&#39;]&#34;.format(param)
        # NOISE
        elif param[0:5] == &#39;NOISE&#39;:
            # type of noise
            if param[-4:] == &#39;NAME&#39;:
                return &#34;[&#39;GEOMETRY&#39;][&#39;{0}&#39;][&#39;{1}&#39;]&#34;.format(configuration, param.split(&#39;-&#39;)[0])
            # noise properties
            else:
                noise_name = self.config_dict[&#39;GEOMETRY&#39;][configuration][param.split(&#39;-&#39;)[0]]
                for k, v in self.config_dict[&#39;SPECIES&#39;].items():
                    for v_key in v.keys():
                        if v_key[0:5] == &#39;NOISE&#39;:
                            if v[&#39;NAME&#39;] == noise_name:
                                return &#34;[&#39;SPECIES&#39;][&#39;{0}&#39;][&#39;PARAMETERS&#39;][&#39;{1}&#39;]&#34;.format(k, param.split(&#39;-&#39;)[-1])
            
        # GEOMETRY and SPECIES
        elif param[0:5] == &#39;PLANE&#39;:
            # redshift
            if param[-8:] == &#39;REDSHIFT&#39;:
                return &#34;[&#39;GEOMETRY&#39;][&#39;{0}&#39;][&#39;{1}&#39;][&#39;PARAMETERS&#39;][&#39;REDSHIFT&#39;]&#34;.format(configuration, param.split(&#39;-&#39;)[0])
            # timeseries - not available yet
            
            # species
            else:
                obj_name = self.config_dict[&#39;GEOMETRY&#39;][configuration][param.split(&#39;-&#39;)[0]][param.split(&#39;-&#39;)[1]]
                for k, v in self.config_dict[&#39;SPECIES&#39;].items():
                    if &#39;NAME&#39; in v.keys():
                        if obj_name == self.config_dict[&#39;SPECIES&#39;][k][&#39;NAME&#39;]:
                            return &#34;[&#39;SPECIES&#39;][&#39;{0}&#39;][&#39;{1}&#39;][&#39;PARAMETERS&#39;][&#39;{2}&#39;]&#34;.format(k, param.split(&#39;-&#39;)[2], param.split(&#39;-&#39;)[-1])
                print(&#34;If you&#39;re seeing this message, you&#39;re trying to update something I wasn&#39;t prepared for.\nShoot me a message on Slack&#34;)
        else:
            print(&#34;If you&#39;re seeing this message, you&#39;re trying to update something I wasn&#39;t prepared for.\nShoot me a message on Slack&#34;)

        
    def regenerate(self, **make_dataset_args):
        &#34;&#34;&#34;
        Using the dictionary stored in self.config_dict, make a new dataset
        
        Args:
            make_dataset_args (dict): arguments supplied to make_dataset when original dataset was generated
        &#34;&#34;&#34;
        params = dict(**make_dataset_args)
        params[&#39;config&#39;] = self.config_dict
        params[&#39;dataset&#39;] = self
        make_dataset(**params)
        return


    def search(self, param_name):
        &#34;&#34;&#34;
        Find all USERDIST column headers for a parameter.
        
        Args:
            param_name (str): the parameter name to search for
            
        Returns:
            dict: keys contain object names, values contain a list of all possible USERDIST column headers
        &#34;&#34;&#34;
        obj_paths = [&#39;[&#34;&#39; + x[9:].replace(&#39;.&#39;, &#39;&#34;][&#34;&#39;) + &#39;&#34;]&#39; for x in self.config_dict.keypaths() if x.startswith(&#34;GEOMETRY&#34;) and x.find(&#34;OBJECT_&#34;) != -1]
        obj_names = []
        for x in obj_paths:
            obj_names.append(eval(&#39;self.config_dict[&#34;GEOMETRY&#34;]&#39; + x))
        species_paths = [&#39;[&#34;&#39; + x.replace(&#39;.&#39;, &#39;&#34;][&#34;&#39;) + &#39;&#34;]&#39; for x in self.config_dict.keypaths() if x.startswith(&#34;SPECIES&#34;) and x.endswith(&#34;NAME&#34;) and x.find(&#34;LIGHT_PROFILE_&#34;) == -1 and x.find(&#34;MASS_PROFILE_&#34;) == -1 and x.find(&#34;SHEAR_PROFILE_&#34;) == -1]
        species_names = []
        for x in species_paths:
            species_names.append(eval(&#39;self.config_dict&#39; + x))
    
        paths = []
        for obj_idx, obj_name in enumerate(obj_names):
            for species_idx, species_name in enumerate(species_names):
                if obj_name == species_name:
                    paths.append({&#39;name&#39;: obj_name,
                                  &#39;obj_path&#39;: obj_paths[obj_idx].replace(&#39;&#34;][&#34;&#39;, &#39;.&#39;)[2:-2],
                                  &#39;spe_path&#39;: species_paths[species_idx].replace(&#39;&#34;][&#34;&#39;, &#39;.&#39;)[2:-6]})
                    
        output_dict = {} 
        for p in paths:

            hr_paths = [p[&#39;obj_path&#39;] + &#39;.&#39; + x.replace(&#39;.PARAMETERS.&#39;, &#39;.&#39;)[len(p[&#39;spe_path&#39;]):] for x in self.config_dict.keypaths() if x.startswith(p[&#39;spe_path&#39;]) and x.find(param_name) != -1]
            output_paths = []
            for hr_path in hr_paths:
                if hr_path.find(&#39;DISTRIBUTION&#39;) != -1:
                    # not recommended to use this feature to update parameters in distributions
                    continue
                
                for band in self.bands:
                    output_paths.append(hr_path.replace(&#39;.&#39;, &#39;-&#39;) + &#39;-&#39; + band)
                    
            if len(output_paths) == 0:
                continue

            if p[&#39;name&#39;] in output_dict.keys():
                output_dict[p[&#39;name&#39;]] += output_paths
            else:
                output_dict[p[&#39;name&#39;]] = output_paths
            
        return output_dict</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="deeplenstronomy.deeplenstronomy.Dataset.regenerate"><code class="name flex">
<span>def <span class="ident">regenerate</span></span>(<span>self, **make_dataset_args)</span>
</code></dt>
<dd>
<div class="desc"><p>Using the dictionary stored in self.config_dict, make a new dataset</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>make_dataset_args</code></strong> :&ensp;<code>dict</code></dt>
<dd>arguments supplied to make_dataset when original dataset was generated</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regenerate(self, **make_dataset_args):
    &#34;&#34;&#34;
    Using the dictionary stored in self.config_dict, make a new dataset
    
    Args:
        make_dataset_args (dict): arguments supplied to make_dataset when original dataset was generated
    &#34;&#34;&#34;
    params = dict(**make_dataset_args)
    params[&#39;config&#39;] = self.config_dict
    params[&#39;dataset&#39;] = self
    make_dataset(**params)
    return</code></pre>
</details>
</dd>
<dt id="deeplenstronomy.deeplenstronomy.Dataset.search"><code class="name flex">
<span>def <span class="ident">search</span></span>(<span>self, param_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Find all USERDIST column headers for a parameter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>param_name</code></strong> :&ensp;<code>str</code></dt>
<dd>the parameter name to search for</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>keys contain object names, values contain a list of all possible USERDIST column headers</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search(self, param_name):
    &#34;&#34;&#34;
    Find all USERDIST column headers for a parameter.
    
    Args:
        param_name (str): the parameter name to search for
        
    Returns:
        dict: keys contain object names, values contain a list of all possible USERDIST column headers
    &#34;&#34;&#34;
    obj_paths = [&#39;[&#34;&#39; + x[9:].replace(&#39;.&#39;, &#39;&#34;][&#34;&#39;) + &#39;&#34;]&#39; for x in self.config_dict.keypaths() if x.startswith(&#34;GEOMETRY&#34;) and x.find(&#34;OBJECT_&#34;) != -1]
    obj_names = []
    for x in obj_paths:
        obj_names.append(eval(&#39;self.config_dict[&#34;GEOMETRY&#34;]&#39; + x))
    species_paths = [&#39;[&#34;&#39; + x.replace(&#39;.&#39;, &#39;&#34;][&#34;&#39;) + &#39;&#34;]&#39; for x in self.config_dict.keypaths() if x.startswith(&#34;SPECIES&#34;) and x.endswith(&#34;NAME&#34;) and x.find(&#34;LIGHT_PROFILE_&#34;) == -1 and x.find(&#34;MASS_PROFILE_&#34;) == -1 and x.find(&#34;SHEAR_PROFILE_&#34;) == -1]
    species_names = []
    for x in species_paths:
        species_names.append(eval(&#39;self.config_dict&#39; + x))

    paths = []
    for obj_idx, obj_name in enumerate(obj_names):
        for species_idx, species_name in enumerate(species_names):
            if obj_name == species_name:
                paths.append({&#39;name&#39;: obj_name,
                              &#39;obj_path&#39;: obj_paths[obj_idx].replace(&#39;&#34;][&#34;&#39;, &#39;.&#39;)[2:-2],
                              &#39;spe_path&#39;: species_paths[species_idx].replace(&#39;&#34;][&#34;&#39;, &#39;.&#39;)[2:-6]})
                
    output_dict = {} 
    for p in paths:

        hr_paths = [p[&#39;obj_path&#39;] + &#39;.&#39; + x.replace(&#39;.PARAMETERS.&#39;, &#39;.&#39;)[len(p[&#39;spe_path&#39;]):] for x in self.config_dict.keypaths() if x.startswith(p[&#39;spe_path&#39;]) and x.find(param_name) != -1]
        output_paths = []
        for hr_path in hr_paths:
            if hr_path.find(&#39;DISTRIBUTION&#39;) != -1:
                # not recommended to use this feature to update parameters in distributions
                continue
            
            for band in self.bands:
                output_paths.append(hr_path.replace(&#39;.&#39;, &#39;-&#39;) + &#39;-&#39; + band)
                
        if len(output_paths) == 0:
            continue

        if p[&#39;name&#39;] in output_dict.keys():
            output_dict[p[&#39;name&#39;]] += output_paths
        else:
            output_dict[p[&#39;name&#39;]] = output_paths
        
    return output_dict</code></pre>
</details>
</dd>
<dt id="deeplenstronomy.deeplenstronomy.Dataset.update_param"><code class="name flex">
<span>def <span class="ident">update_param</span></span>(<span>self, new_param_dict, configuration)</span>
</code></dt>
<dd>
<div class="desc"><p>Update single parameters to new values.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>new_param_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>{'param_1_name': new_value_1, 'param_2_name': new_value_2, &hellip;}</dd>
<dt><strong><code>configuration</code></strong> :&ensp;<code>str</code></dt>
<dd>like 'CONFIGURATION_1', 'CONFIGURATION_2', etc&hellip;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_param(self, new_param_dict, configuration):
    &#34;&#34;&#34;
    Update single parameters to new values.

    Args:
        new_param_dict (dict): {&#39;param_1_name&#39;: new_value_1, &#39;param_2_name&#39;: new_value_2, ...}
        configuration (str): like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc...     
    &#34;&#34;&#34;
    # Put in the updated values
    for new_param, new_value in new_param_dict.items():
        exec(&#34;self.config_dict&#34; + self._locate(new_param, configuration) + &#34; = new_value&#34;)
        
    return</code></pre>
</details>
</dd>
<dt id="deeplenstronomy.deeplenstronomy.Dataset.update_param_dist"><code class="name flex">
<span>def <span class="ident">update_param_dist</span></span>(<span>self, new_param_dist_dict, configuration)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the distribution from which a parameter is drawn.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>new_param_dist_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Should look like this<pre><code>{'param_1_name': {'name': 'uniform',
                'parameters': {'minimum': new_value_1,
                               'maximum': new_value_2}},
'param_2_name': {'name': 'uniform',
                'parameters': {'minimum': new_value_3,
                               'maximum': new_value_4}}, ...}
</code></pre>
</dd>
<dt><strong><code>configuration</code></strong> :&ensp;<code>str</code></dt>
<dd>like 'CONFIGURATION_1', 'CONFIGURATION_2', etc&hellip;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_param_dist(self, new_param_dist_dict, configuration):
    &#34;&#34;&#34;
    Update the distribution from which a parameter is drawn.

    Args:
        new_param_dist_dict (dict): 
          Should look like this
          
              {&#39;param_1_name&#39;: {&#39;name&#39;: &#39;uniform&#39;,
                              &#39;parameters&#39;: {&#39;minimum&#39;: new_value_1,
                                             &#39;maximum&#39;: new_value_2}},
              &#39;param_2_name&#39;: {&#39;name&#39;: &#39;uniform&#39;,
                              &#39;parameters&#39;: {&#39;minimum&#39;: new_value_3,
                                             &#39;maximum&#39;: new_value_4}}, ...}   
        
        configuration (str):  like &#39;CONFIGURATION_1&#39;, &#39;CONFIGURATION_2&#39;, etc...
    &#34;&#34;&#34;
    # Put in the updated distributions
    for new_param, new_dist_info in new_param_dist_dict.items():
        location = self._locate(new_param, configuration)
        exec(&#34;self.config_dict&#34; + location + &#34; = {&#39;DISTRIBUTION&#39;: {&#39;NAME&#39;: &#39;&#39;, &#39;PARAMETERS&#39;: {}}}&#34;)
        exec(&#34;self.config_dict&#34; + location + &#34;[&#39;DISTRIBUTION&#39;][&#39;NAME&#39;] = new_dist_info[&#39;name&#39;]&#34;)
        for new_dist_param, new_dist_param_value in new_dist_info[&#39;parameters&#39;].items():
            exec(&#34;self.config_dict&#34; + location + &#34;[&#39;DISTRIBUTION&#39;][&#39;PARAMETERS&#39;][new_dist_param] = new_dist_param_value&#34;)

    return</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="deeplenstronomy" href="index.html">deeplenstronomy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="deeplenstronomy.deeplenstronomy.make_dataset" href="#deeplenstronomy.deeplenstronomy.make_dataset">make_dataset</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="deeplenstronomy.deeplenstronomy.Dataset" href="#deeplenstronomy.deeplenstronomy.Dataset">Dataset</a></code></h4>
<ul class="">
<li><code><a title="deeplenstronomy.deeplenstronomy.Dataset.regenerate" href="#deeplenstronomy.deeplenstronomy.Dataset.regenerate">regenerate</a></code></li>
<li><code><a title="deeplenstronomy.deeplenstronomy.Dataset.search" href="#deeplenstronomy.deeplenstronomy.Dataset.search">search</a></code></li>
<li><code><a title="deeplenstronomy.deeplenstronomy.Dataset.update_param" href="#deeplenstronomy.deeplenstronomy.Dataset.update_param">update_param</a></code></li>
<li><code><a title="deeplenstronomy.deeplenstronomy.Dataset.update_param_dist" href="#deeplenstronomy.deeplenstronomy.Dataset.update_param_dist">update_param_dist</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>