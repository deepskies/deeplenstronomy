{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Classification and Regression\n",
    "\n",
    "`deeplenstronomy` is designed for the purpose of facilitating machine and deep-learning studies of strong gravitational lensing. Supervised problems in these fields are typically framed as either classification problems or regression problems. This notebook will illustrate how you might utilize the features of `deeplenstronomy` to aid the development of your classification and regression algorithms.\n",
    "\n",
    "Let's start by simulating a dataset with the `demo_distributions.yaml` file, and we'll also utilize the `solve_lens_equation` and `return_planes` arguments of `deeplenstronomy.makedataset()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplenstronomy.deeplenstronomy as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering main organization loop\n",
      "Organizing CONFIGURATION_1\n",
      "Generating images for CONFIGURATION_1\n",
      "\tProgress: 100.0 %  ---  Elapsed Time: 0 H 1 M 57 S\n"
     ]
    }
   ],
   "source": [
    "dataset = dl.make_dataset(\"data/demo_distributions.yaml\", solve_lens_equation=True, return_planes=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### A simple, straightforward approach\n",
    "\n",
    "For classification tasks, we are trying to predict a discretely-valued variable. The simplest approach to do this in `deeplenstronomy` is to classify the images from one configuration against the images in another configuration, with the configuration label serving as your discrete variable. If you take that simple approach, structure each `CONFIGURATION` section in the `GEOMETRY` section to be one of the classes in your classification problem.\n",
    "\n",
    "### A classic approach\n",
    "\n",
    "In strong lensing searches, the terminology of \"quads\" and \"doubles\" are often used to describe the type of lensing going on (refering to the number of images of the source galaxy produced by the lensing). If you would like to classify based on the number of images of the source object, you can use the `solve_lens_equation` argument of `deeplenstronomy.makedataset()` to your advantage.\n",
    "\n",
    "Setting this argument to `True` will add several columns to your dataset's metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_source_images-g</th>\n",
       "      <th>num_source_images-r</th>\n",
       "      <th>num_source_images-i</th>\n",
       "      <th>num_source_images-z</th>\n",
       "      <th>num_source_images-Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_source_images-g  num_source_images-r  num_source_images-i  \\\n",
       "0                    4                    4                    4   \n",
       "1                    4                    4                    4   \n",
       "2                    4                    4                    4   \n",
       "3                    4                    4                    4   \n",
       "4                    4                    4                    4   \n",
       "\n",
       "   num_source_images-z  num_source_images-Y  \n",
       "0                    4                    4  \n",
       "1                    4                    4  \n",
       "2                    4                    4  \n",
       "3                    4                    4  \n",
       "4                    4                    4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_cols = ['num_source_images-g',\n",
    "               'num_source_images-r',\n",
    "               'num_source_images-i',\n",
    "               'num_source_images-z',\n",
    "               'num_source_images-Y']\n",
    "\n",
    "dataset.CONFIGURATION_1_metadata[metric_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be a column of `num_source_images` for each band you choose to simulate. Using these columns you can determine which images contain quads, doubles, or no lensing. There are also columns such as `x_mins_g`, `y_mins_g`, `x_mins_r`, etc. for each band. These columns contain the information of the locations of each of the found positions of the lensed source object in your images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Traditionally, strong lensing has been treated as a classification problem. However, there exist corner cases of slightly aligned galaxies that may produce small amounts of lensing as opposed to magnificent arcs and multiple images. If these corner cases exist in your training dataset, your classification algorithm may struggle with them. Framing lens detection as a regression problem is an interesting solution where instead of asking \"Is this a lens?\" or \"Is this a quad?\" you ask \"How lensy is this image?\"\n",
    "\n",
    "To make this type of approach possible, you need to define a continuous variable that reflects the amount of lensing in the system. A mathematical approach to this is by calculating a quantity called the \"Strong Lensing Cross Section,\" and as an open source framework, you are welcome to submit a pull-request to add this calculation to `deeplenstronomy`. \n",
    "\n",
    "Another option that is possible with the current implementation of `deeplenstronomy` is to utilize the light from the source plane separate from all other light. Naively, if there is a lot of lensing going on, there will be a lot of light in the source plane, and if there is only a small amount of lensing then one would also expect a small amount of light in the source plane. This argument has to be normalized by the un-lensed brightness of the objects in the source plane, but is still a useable metric.\n",
    "\n",
    "You can access this information by setting the `return_planes` argument to `True`. When you use this setting, your dataset will gain a new attribute for each configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONFIGURATION_1_planes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(dataset) if x.endswith('planes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.CONFIGURATION_1_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 4, 5, 100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.CONFIGURATION_1_planes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `planes` for each configuration will be a numpy array with the following dimension structure:\n",
    "\n",
    "- 0: the index of the image\n",
    "- 1: the index of the plane\n",
    "- 2: the index of the band\n",
    "- 3: the row index in each image\n",
    "- 4: the column index in each image\n",
    "\n",
    "Specifically, the `plane` axis is ordered as (\"Lens Plane\", \"Source Plane\", \"Point Sources\", \"Noise\"). Thus you can access all the source planes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_planes = dataset.CONFIGURATION_1_planes[:,1,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, you can define a metric of your choice to characterize the amount of lensing going on. \n",
    "\n",
    "A simple example could be the number of pixels with brightness above a certain threshold in a single band (the $g$-band in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1398 1156  492 1714 2832  434  526  654  800 1552 1430 1258  274  818\n",
      " 1190  720  418  724  620  798  724 3306  804  954  464  488  488 1276\n",
      "  800  646  818 4962 1258  496  718 1548  470  588  800  670  244  956\n",
      "  502  474  508  818 1478 3106 2286  998  778  522  468  614 2442  856\n",
      "  566 1156 2688 1146  424  352  356  856 1198  218  438 1098  854 1002\n",
      "  398  790  472  806  388  466  646  326 1076  994  882 1998  510  928\n",
      " 1114 1056  540  634  880 2186 1616  656  782  642 1766 1502  704  402\n",
      "  514 1098 2198  236  592  422 2054  946  416  944  754 1536 1028  630\n",
      " 1548  548 1856 1012  888 1568  550 1498 1684  576  634  350 1618 1122\n",
      "  184 1358  458  872 1478  820  952 2264 1730 1710  444 1598  750  412\n",
      "  882  420 1178 1218 1574 1318 1890  680 1356  578  546  692  960  994\n",
      " 1118  830 1664 1062 1050  642  354  444 3306  344  788 1554  832 1232\n",
      " 1088  698  364  764  602  742  534 1116 1676  812  948 1604 1546 1294\n",
      "  558  854  914 1034  378 1824 1584  430 1024  838 1780 1300  514  814\n",
      "  880  530 1242  616  622 1128  562  456 2164 1862  570  606 1290 1644\n",
      " 2078 1366 1624  828  484  614  832  978  784 1542 2006  830  374 1092\n",
      "  642 2138 1610  418  568 1318  886  738  704  748 1380  474  508  532\n",
      "  666  674  928  502  454 1582 1050  970  788 1086  336 1252]\n"
     ]
    }
   ],
   "source": [
    "threshold = 5.0\n",
    "metric = np.sum(np.where(source_planes[:,0,:,:] > threshold, 1, 0), axis=(-1,-2))\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I did not perform any normalization of the pixel values by the brightness of the objects simulated, nor did I normalize the number of pixels above the threshold by the angular sizes of the objects simulated, but these quantities are present in the `dataset.CONFIGURATION_1.metadata`. If these other two properties of the simulated dat were accounted for, then this metric could potentially frame the problem of lens detection as a regression problem. The purpose of this specific example, though, was to display how to pull information out of the individual planes and present the general concept of approaching strong lens searches with regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
